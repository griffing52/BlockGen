{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862d55b9",
   "metadata": {},
   "source": [
    "# Attention-based Autoregressive Structure Generation\n",
    "\n",
    "This notebook trains a **causal Transformer** (self-attention) that autoregressively generates voxel structures of variable sizes.\n",
    "\n",
    "## Key idea\n",
    "We serialize each structure as:\n",
    "- `<BOS>`\n",
    "- `SIZE_X_n`, `SIZE_Y_n`, `SIZE_Z_n`\n",
    "- flattened block-ID tokens in XYZ scan order\n",
    "- `<EOS>`\n",
    "\n",
    "At generation time, the model predicts size tokens and then voxel tokens, allowing different output sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b377ab7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "torch: 2.10.0+cu128\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from blockgen.utils.data_loader import load_schematic\n",
    "from blockgen.utils.data import Structure\n",
    "from blockgen.renderer.render import render_schem\n",
    "from blockgen.models import VoxelTransformerAR\n",
    "\n",
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "print('torch:', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4a95cf",
   "metadata": {},
   "source": [
    "## 1) Load + preprocess structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07804ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schematics used: 1000\n",
      "example shape: (11, 4, 10)\n"
     ]
    }
   ],
   "source": [
    "repo_root = Path.cwd()\n",
    "if not (repo_root / 'data' / 'raw').exists():\n",
    "    repo_root = repo_root.parent\n",
    "\n",
    "raw_dir = repo_root / 'data' / 'raw'\n",
    "all_paths = sorted(raw_dir.glob('*.schematic'))\n",
    "\n",
    "num_examples = 1000\n",
    "max_dim = 12\n",
    "max_size_token = 12\n",
    "air_block_id = 0\n",
    "\n",
    "paths = all_paths[:num_examples]\n",
    "print('schematics used:', len(paths))\n",
    "\n",
    "\n",
    "def preprocess_structure(path, max_dim=12):\n",
    "    schem = load_schematic(str(path))\n",
    "    st = Structure.from_schematic(schem, source_path=str(path))\n",
    "    st = st.crop_to_non_air()\n",
    "    st = st.downsample(max_dim=max_dim)\n",
    "    sx, sy, sz = st.shape\n",
    "\n",
    "    # Clip to representable size tokens\n",
    "    sx = min(sx, max_size_token)\n",
    "    sy = min(sy, max_size_token)\n",
    "    sz = min(sz, max_size_token)\n",
    "\n",
    "    ids = st.block_ids[:sx, :sy, :sz].astype(np.int32)\n",
    "    return ids\n",
    "\n",
    "\n",
    "grids = [preprocess_structure(path, max_dim=max_dim) for path in paths]\n",
    "print('example shape:', grids[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d9d3b",
   "metadata": {},
   "source": [
    "## 2) Build tokenizer with size tokens + block tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09ac32ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 250\n",
      "block token count: 210\n",
      "air token: 129\n"
     ]
    }
   ],
   "source": [
    "special_tokens = ['<PAD>', '<BOS>', '<EOS>', '<UNK>']\n",
    "size_tokens = []\n",
    "for n in range(1, max_size_token + 1):\n",
    "    size_tokens.extend([f'SIZE_X_{n}', f'SIZE_Y_{n}', f'SIZE_Z_{n}'])\n",
    "\n",
    "block_counter = Counter()\n",
    "for g in grids:\n",
    "    block_counter.update(g.reshape(-1).tolist())\n",
    "\n",
    "observed_block_ids = sorted(int(x) for x in block_counter.keys())\n",
    "block_tokens = [f'BID_{bid}' for bid in observed_block_ids]\n",
    "\n",
    "all_tokens = special_tokens + size_tokens + block_tokens\n",
    "stoi = {tok: i for i, tok in enumerate(all_tokens)}\n",
    "itos = {i: tok for tok, i in stoi.items()}\n",
    "\n",
    "pad_idx = stoi['<PAD>']\n",
    "bos_idx = stoi['<BOS>']\n",
    "eos_idx = stoi['<EOS>']\n",
    "unk_idx = stoi['<UNK>']\n",
    "\n",
    "air_token = stoi.get('BID_0', unk_idx)\n",
    "vocab_size = len(stoi)\n",
    "\n",
    "print('vocab size:', vocab_size)\n",
    "print('block token count:', len(block_tokens))\n",
    "print('air token:', air_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2231cc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sequence length: 1733\n"
     ]
    }
   ],
   "source": [
    "def size_to_tokens(shape):\n",
    "    sx, sy, sz = shape\n",
    "    return [stoi[f'SIZE_X_{sx}'], stoi[f'SIZE_Y_{sy}'], stoi[f'SIZE_Z_{sz}']]\n",
    "\n",
    "\n",
    "def block_id_to_token(block_id):\n",
    "    tok = f'BID_{int(block_id)}'\n",
    "    return stoi.get(tok, unk_idx)\n",
    "\n",
    "\n",
    "def token_to_block_id(token_idx):\n",
    "    tok = itos.get(int(token_idx), '<UNK>')\n",
    "    if isinstance(tok, str) and tok.startswith('BID_'):\n",
    "        return int(tok.split('_', 1)[1])\n",
    "    return 0\n",
    "\n",
    "\n",
    "def serialize_grid(grid):\n",
    "    sx, sy, sz = grid.shape\n",
    "    seq = [bos_idx]\n",
    "    seq.extend(size_to_tokens((sx, sy, sz)))\n",
    "    seq.extend([block_id_to_token(x) for x in grid.reshape(-1).tolist()])\n",
    "    seq.append(eos_idx)\n",
    "    return seq\n",
    "\n",
    "\n",
    "sequences = [serialize_grid(grid) for grid in grids]\n",
    "max_seq_len = max(len(s) for s in sequences)\n",
    "print('max sequence length:', max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8912c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train examples: 187 test examples: 33\n"
     ]
    }
   ],
   "source": [
    "perm = np.random.permutation(len(sequences))\n",
    "n_train = int(0.85 * len(sequences))\n",
    "train_ids = perm[:n_train]\n",
    "test_ids = perm[n_train:]\n",
    "\n",
    "train_sequences = [sequences[i] for i in train_ids]\n",
    "test_sequences = [sequences[i] for i in test_ids]\n",
    "\n",
    "train_hashes = {tuple(seq) for seq in train_sequences}\n",
    "\n",
    "\n",
    "class ARTokenDataset(Dataset):\n",
    "    def __init__(self, seqs):\n",
    "        self.seqs = seqs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = torch.tensor(self.seqs[idx], dtype=torch.long)\n",
    "        inp = seq[:-1]\n",
    "        tgt = seq[1:]\n",
    "        return inp, tgt\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    max_len = max(x.shape[0] for x in xs)\n",
    "\n",
    "    x_pad = torch.full((len(xs), max_len), pad_idx, dtype=torch.long)\n",
    "    y_pad = torch.full((len(xs), max_len), pad_idx, dtype=torch.long)\n",
    "    pad_mask = torch.ones((len(xs), max_len), dtype=torch.bool)\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(xs, ys)):\n",
    "        n = x.shape[0]\n",
    "        x_pad[i, :n] = x\n",
    "        y_pad[i, :n] = y\n",
    "        pad_mask[i, :n] = False\n",
    "\n",
    "    return x_pad, y_pad, pad_mask\n",
    "\n",
    "\n",
    "train_loader = DataLoader(ARTokenDataset(train_sequences), batch_size=12, shuffle=True, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(ARTokenDataset(test_sequences), batch_size=12, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "print('train examples:', len(train_sequences), 'test examples:', len(test_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f25673",
   "metadata": {},
   "source": [
    "## 3) Define and train attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70a049b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train_loss=2.3029 | val_loss=1.5088 | val_ppl=4.52\n",
      "epoch 02 | train_loss=1.4593 | val_loss=1.2139 | val_ppl=3.37\n",
      "epoch 03 | train_loss=1.2927 | val_loss=1.1099 | val_ppl=3.03\n",
      "epoch 04 | train_loss=1.1625 | val_loss=1.0407 | val_ppl=2.83\n",
      "epoch 05 | train_loss=1.0860 | val_loss=0.9894 | val_ppl=2.69\n",
      "epoch 06 | train_loss=1.0234 | val_loss=0.9548 | val_ppl=2.60\n",
      "epoch 07 | train_loss=1.0110 | val_loss=0.9326 | val_ppl=2.54\n",
      "epoch 08 | train_loss=0.9759 | val_loss=0.9185 | val_ppl=2.51\n"
     ]
    }
   ],
   "source": [
    "model = VoxelTransformerAR(\n",
    "    vocab_size=vocab_size,\n",
    "    max_seq_len=max_seq_len,\n",
    "    d_model=192,\n",
    "    nhead=6,\n",
    "    num_layers=6,\n",
    "    dim_feedforward=768,\n",
    "    dropout=0.1,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "def token_loss(logits, targets, ignore_index):\n",
    "    b, t, v = logits.shape\n",
    "    return F.cross_entropy(logits.reshape(b * t, v), targets.reshape(b * t), ignore_index=ignore_index)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for x, y, pad_mask in loader:\n",
    "        x, y, pad_mask = x.to(device), y.to(device), pad_mask.to(device)\n",
    "        logits = model(x, pad_mask=pad_mask)\n",
    "        loss = token_loss(logits, y, ignore_index=pad_idx)\n",
    "        losses.append(float(loss.item()))\n",
    "\n",
    "    mean_loss = float(np.mean(losses)) if losses else 0.0\n",
    "    ppl = float(np.exp(mean_loss))\n",
    "    return mean_loss, ppl\n",
    "\n",
    "\n",
    "epochs = 8\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for x, y, pad_mask in train_loader:\n",
    "        x, y, pad_mask = x.to(device), y.to(device), pad_mask.to(device)\n",
    "\n",
    "        logits = model(x, pad_mask=pad_mask)\n",
    "        loss = token_loss(logits, y, ignore_index=pad_idx)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(float(loss.item()))\n",
    "\n",
    "    train_loss = float(np.mean(train_losses))\n",
    "    val_loss, val_ppl = evaluate(test_loader)\n",
    "    print(f'epoch {epoch:02d} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | val_ppl={val_ppl:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d1678",
   "metadata": {},
   "source": [
    "## 4) Autoregressive sampling with variable sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ff26359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next_token(logits, temperature=1.0, top_k=32):\n",
    "    logits = logits / max(temperature, 1e-6)\n",
    "    if top_k is not None and top_k > 0 and top_k < logits.shape[-1]:\n",
    "        vals, idxs = torch.topk(logits, k=top_k, dim=-1)\n",
    "        probs = torch.softmax(vals, dim=-1)\n",
    "        pick = torch.multinomial(probs, num_samples=1)\n",
    "        return idxs.gather(-1, pick)\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    return torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "\n",
    "def parse_size_token(token_idx, axis):\n",
    "    tok = itos.get(int(token_idx), '')\n",
    "    prefix = f'SIZE_{axis}_'\n",
    "    if isinstance(tok, str) and tok.startswith(prefix):\n",
    "        return int(tok[len(prefix):])\n",
    "    return None\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_structure_tokens(model, temperature=0.95, top_k=32):\n",
    "    model.eval()\n",
    "    seq = [bos_idx]\n",
    "\n",
    "    # 1) sample size tokens\n",
    "    for axis in ['X', 'Y', 'Z']:\n",
    "        x = torch.tensor([seq], dtype=torch.long, device=device)\n",
    "        logits = model(x)[:, -1, :]\n",
    "\n",
    "        # Restrict to valid size tokens for the requested axis\n",
    "        valid = [stoi[f'SIZE_{axis}_{n}'] for n in range(1, max_size_token + 1)]\n",
    "        restricted = torch.full_like(logits, -1e9)\n",
    "        restricted[:, valid] = logits[:, valid]\n",
    "\n",
    "        tok = int(sample_next_token(restricted, temperature=temperature, top_k=min(top_k, len(valid))).item())\n",
    "        seq.append(tok)\n",
    "\n",
    "    sx = parse_size_token(seq[1], 'X') or 1\n",
    "    sy = parse_size_token(seq[2], 'Y') or 1\n",
    "    sz = parse_size_token(seq[3], 'Z') or 1\n",
    "\n",
    "    n_voxels = sx * sy * sz\n",
    "\n",
    "    # 2) sample voxel tokens\n",
    "    block_vocab = [stoi[f'BID_{bid}'] for bid in observed_block_ids if f'BID_{bid}' in stoi]\n",
    "\n",
    "    for _ in range(n_voxels):\n",
    "        x = torch.tensor([seq], dtype=torch.long, device=device)\n",
    "        logits = model(x)[:, -1, :]\n",
    "\n",
    "        restricted = torch.full_like(logits, -1e9)\n",
    "        restricted[:, block_vocab] = logits[:, block_vocab]\n",
    "        tok = int(sample_next_token(restricted, temperature=temperature, top_k=min(top_k, len(block_vocab))).item())\n",
    "        seq.append(tok)\n",
    "\n",
    "    seq.append(eos_idx)\n",
    "    return seq\n",
    "\n",
    "\n",
    "def decode_tokens_to_structure(seq):\n",
    "    sx = parse_size_token(seq[1], 'X') or 1\n",
    "    sy = parse_size_token(seq[2], 'Y') or 1\n",
    "    sz = parse_size_token(seq[3], 'Z') or 1\n",
    "\n",
    "    voxel_tokens = seq[4:4 + sx * sy * sz]\n",
    "    block_ids = np.array([token_to_block_id(t) for t in voxel_tokens], dtype=np.int32).reshape((sx, sy, sz))\n",
    "    block_data = np.zeros_like(block_ids, dtype=np.int32)\n",
    "    return Structure(block_ids=block_ids, block_data=block_data, source_path='generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab961cba",
   "metadata": {},
   "outputs": [
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(generated_sequences) < target_samples \u001b[38;5;129;01mand\u001b[39;00m attempts < max_attempts:\n\u001b[32m      9\u001b[39m     attempts += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     seq = \u001b[43mgenerate_structure_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# novelty filter: skip exact training sequences\u001b[39;00m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(seq) \u001b[38;5;129;01min\u001b[39;00m train_hashes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/gen/BlockGen/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:124\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# pyrefly: ignore [bad-context-manager]\u001b[39;00m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mgenerate_structure_tokens\u001b[39m\u001b[34m(model, temperature, top_k)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# 1) sample size tokens\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mY\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mZ\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     x = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     logits = model(x)[:, -\u001b[32m1\u001b[39m, :]\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Restrict to valid size tokens for the requested axis\u001b[39;00m\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "generated_sequences = []\n",
    "generated_structures = []\n",
    "\n",
    "target_samples = 4\n",
    "attempts = 0\n",
    "max_attempts = 40\n",
    "\n",
    "while len(generated_sequences) < target_samples and attempts < max_attempts:\n",
    "    attempts += 1\n",
    "    seq = generate_structure_tokens(model, temperature=1.0, top_k=24)\n",
    "\n",
    "    # novelty filter: skip exact training sequences\n",
    "    if tuple(seq) in train_hashes:\n",
    "        continue\n",
    "\n",
    "    generated_sequences.append(seq)\n",
    "    generated_structures.append(decode_tokens_to_structure(seq))\n",
    "\n",
    "print('generated novel samples:', len(generated_structures), 'in attempts:', attempts)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "for i, st in enumerate(generated_structures, start=1):\n",
    "    ax = fig.add_subplot(2, 2, i, projection='3d')\n",
    "    render_schem(st, ax=ax, show=False, crop_non_air=True, max_dim=12)\n",
    "    ax.set_title(f'Generated {i} | shape={st.shape}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100b3f0",
   "metadata": {},
   "source": [
    "## 5) Compare generated distribution to training distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bbadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_counter = Counter()\n",
    "for seq in train_sequences:\n",
    "    for tok in seq:\n",
    "        if isinstance(tok, int) and itos.get(tok, '').startswith('BID_'):\n",
    "            real_counter[tok] += 1\n",
    "\n",
    "gen_counter = Counter()\n",
    "for seq in generated_sequences:\n",
    "    for tok in seq:\n",
    "        if isinstance(tok, int) and itos.get(tok, '').startswith('BID_'):\n",
    "            gen_counter[tok] += 1\n",
    "\n",
    "keys = sorted(set(real_counter.keys()) | set(gen_counter.keys()))\n",
    "eps = 1e-9\n",
    "\n",
    "real = np.array([real_counter.get(k, 0) for k in keys], dtype=np.float64)\n",
    "gen = np.array([gen_counter.get(k, 0) for k in keys], dtype=np.float64)\n",
    "\n",
    "real = (real + eps) / (real.sum() + eps * len(real))\n",
    "gen = (gen + eps) / (gen.sum() + eps * len(gen))\n",
    "\n",
    "kl_real_gen = float(np.sum(real * np.log(real / gen)))\n",
    "print('KL(real || generated):', round(kl_real_gen, 4))\n",
    "\n",
    "top_real = [k for k, _ in real_counter.most_common(12)]\n",
    "labels = [itos[k] for k in top_real]\n",
    "rv = [real_counter[k] for k in top_real]\n",
    "gv = [gen_counter.get(k, 0) for k in top_real]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "w = 0.42\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(x - w / 2, rv, width=w, label='real')\n",
    "plt.bar(x + w / 2, gv, width=w, label='generated')\n",
    "plt.xticks(x, labels, rotation=45)\n",
    "plt.title('Top block-token counts: training vs generated')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3c633",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "This model is genuinely autoregressive and attention-based. It can produce variable-size outputs and novel samples, but quality depends on training scale.\n",
    "\n",
    "Recommended upgrades:\n",
    "- train longer and on more schematics\n",
    "- include `block_data` tokens (state/metadata)\n",
    "- add coordinate factorization or hierarchical generation\n",
    "- add validity constraints (e.g., support/physics-inspired checks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
